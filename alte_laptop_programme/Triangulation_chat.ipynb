{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-02T21:05:28.491153Z",
     "start_time": "2025-09-02T21:05:28.073163Z"
    }
   },
   "source": [
    "# laser_triangulation_clean.py\n",
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =======================\n",
    "# User-Parameter\n",
    "# =======================\n",
    "# 1) Bildquellen (nimm einfach zwei Dateien in beliebiger Reihenfolge)\n",
    "IMG_DIR = r\"G:\\Meine Ablage\\Studium\\Master\\3. Semester\\Masterprojekt\\Kamera_Simulationen\\Solidworks\"\n",
    "IMG_PATTERNS = [\"**/*.png\", \"**/*.jpg\", \"**/*.jpeg\"]\n",
    "\n",
    "# 2) Ziel-Aspect-Ratio (Breite:Höhe) – nur benutzen, wenn SolidWorks falsch speichert\n",
    "USE_CROP = True\n",
    "TARGET_AR = (8.5, 11.0)  # width : height\n",
    "\n",
    "# 3) Intrinsics: Entweder HFoV ODER (f und Sensor)\n",
    "USE_FOV = True\n",
    "HFOV_DEG = 39.6  # 50mm Vollformat -> ~39.6° horizontal\n",
    "# Falls du lieber mit Sensor+f rechnest:\n",
    "F_MM = 50.0\n",
    "SENSOR_W_MM = 36.0\n",
    "SENSOR_H_MM = 24.0\n",
    "\n",
    "# 4) Extrinsics: Kamera-Zentren in Weltkoordinaten (mm) + „look-at Ursprung“\n",
    "VC1 = np.array([+25.0, 53.59, 200.0])\n",
    "VC2 = np.array([-25.0, 53.59, 200.0])\n",
    "\n",
    "# 5) Bild-/Kameraachsen-Konvention:\n",
    "# Bild-v zeigt nach unten; für klassische Kamera-Y-nach-oben kannst du flippen:\n",
    "FLIP_IMAGE_Y_TO_CAM = True  # d.h. nach K^{-1} wird d_cam[1] *= -1\n",
    "\n",
    "# =======================\n",
    "# Helper\n",
    "# =======================\n",
    "\n",
    "def list_images(base, patterns):\n",
    "    ims = []\n",
    "    for p in patterns:\n",
    "        ims.extend(glob.glob(os.path.join(base, p), recursive=True))\n",
    "    ims = [f for f in ims if os.path.isfile(f)]\n",
    "    ims.sort()\n",
    "    if len(ims) < 2:\n",
    "        raise FileNotFoundError(\"Mindestens zwei Bilder werden benötigt.\")\n",
    "    return ims[:2]\n",
    "\n",
    "def load_rgb(path):\n",
    "    bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        raise IOError(f\"Bild konnte nicht gelesen werden: {path}\")\n",
    "    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def center_crop_to_ar(img, ar_wh):\n",
    "    \"\"\"Center-Crop auf gewünschte Aspect-Ratio. Gibt Bild + (x0,y0)-Offset zurück.\"\"\"\n",
    "    h, w = img.shape[:2]        # ACHTUNG: (H, W, C)\n",
    "    target = ar_wh[0] / ar_wh[1]\n",
    "    if (w / h) > target:\n",
    "        # zu breit -> Breite kürzen\n",
    "        new_w = int(round(h * target))\n",
    "        x0 = (w - new_w) // 2\n",
    "        y0 = 0\n",
    "        x1 = x0 + new_w\n",
    "        y1 = h\n",
    "    else:\n",
    "        # zu hoch -> Höhe kürzen\n",
    "        new_h = int(round(w / target))\n",
    "        x0 = 0\n",
    "        y0 = (h - new_h) // 2\n",
    "        x1 = w\n",
    "        y1 = y0 + new_h\n",
    "    return img[y0:y1, x0:x1].copy(), (x0, y0)\n",
    "\n",
    "def K_from_fovy(image_shape, fov_y_deg, aspect_ratio=None):\n",
    "    h, w = image_shape[:2]\n",
    "    fov_y = np.deg2rad(fov_y_deg)\n",
    "    fy = h / (2.0 * np.tan(fov_y / 2.0))\n",
    "\n",
    "    if aspect_ratio is None:\n",
    "        aspect_ratio = w / h\n",
    "    fov_x = 2.0 * np.arctan(aspect_ratio * np.tan(fov_y / 2.0))\n",
    "    fx = w / (2.0 * np.tan(fov_x / 2.0))\n",
    "\n",
    "    cx, cy = w / 2.0, h / 2.0\n",
    "    return np.array([[fx, 0,  cx],\n",
    "                     [0,  fy, cy],\n",
    "                     [0,   0,  1.0]], float)\n",
    "\n",
    "\n",
    "def K_from_sensor_f(image_shape, f_mm, sensor_w_mm, sensor_h_mm):\n",
    "    \"\"\"Intrinsics aus f und Sensor (phys.) + Bildgröße.\"\"\"\n",
    "    h, w = image_shape[:2]\n",
    "    fx = (w / sensor_w_mm) * f_mm\n",
    "    fy = (h / sensor_h_mm) * f_mm\n",
    "    cx = w / 2.0\n",
    "    cy = h / 2.0\n",
    "    return np.array([[fx, 0,  cx],\n",
    "                     [0,  fy, cy],\n",
    "                     [0,   0,  1.0]], float)\n",
    "\n",
    "def adjust_K_after_crop(K, crop_offset_xy):\n",
    "    \"\"\"Verschiebt den Hauptpunkt nach Center-Crop (nur Offsets abziehen).\"\"\"\n",
    "    x0, y0 = crop_offset_xy\n",
    "    K_adj = K.copy()\n",
    "    K_adj[0, 2] -= x0\n",
    "    K_adj[1, 2] -= y0\n",
    "    return K_adj\n",
    "\n",
    "def find_red_centroid(img_rgb):\n",
    "    \"\"\"Sehr einfache Rot-Maske + Schwerpunkt (in Pixeln: v=row, u=col).\"\"\"\n",
    "    # Schwellen robust gegen „kräftiges“ Rot (anpassen falls nötig)\n",
    "    lower = np.array([100, 0, 0], dtype=np.uint8)   # RGB min\n",
    "    upper = np.array([255, 80, 80], dtype=np.uint8) # RGB max\n",
    "    mask = cv2.inRange(img_rgb, lower, upper)\n",
    "    if mask.max() == 0:\n",
    "        raise ValueError(\"Keine roten Pixel gefunden – Maske anpassen.\")\n",
    "    com = ndimage.center_of_mass(mask)  # (v,row,  u,col) in float\n",
    "    v, u = float(com[0]), float(com[1])\n",
    "    return (v, u), mask\n",
    "\n",
    "def look_at_R(camera_center, target=np.zeros(3), up_hint=np.array([0, 0, 1.0])):\n",
    "    \"\"\"\n",
    "    Baut R_wc (Spalten = x_c, y_c, z_c im Welt-KS), Kamera blickt zum target.\n",
    "    Roll ist damit durch up_hint festgelegt (falls möglich).\n",
    "    \"\"\"\n",
    "    c = np.asarray(camera_center, float)\n",
    "    zc = (target - c)\n",
    "    zc = zc / np.linalg.norm(zc)\n",
    "\n",
    "    xc = np.cross(up_hint, zc)\n",
    "    if np.linalg.norm(xc) < 1e-9:\n",
    "        # up_hint nahezu parallel -> wähle alternative up\n",
    "        up_hint = np.array([0, 1.0, 0], float)\n",
    "        xc = np.cross(up_hint, zc)\n",
    "    xc = xc / np.linalg.norm(xc)\n",
    "    yc = np.cross(zc, xc)\n",
    "\n",
    "    R = np.column_stack((xc, yc, zc))  # 3x3\n",
    "    # Sicherstellen, dass det(R) ~ 1\n",
    "    if np.linalg.det(R) < 0:\n",
    "        R[:, 1] *= -1.0  # Spiegel korrigieren\n",
    "    return R\n",
    "\n",
    "def pixel_ray_world(u, v, K, R_wc, flip_image_y):\n",
    "    \"\"\"Einheitsstrahlrichtung in Weltkoordinaten aus Pixel (u,v).\"\"\"\n",
    "    d_cam = np.linalg.inv(K) @ np.array([u, v, 1.0], float)\n",
    "    if flip_image_y:\n",
    "        d_cam[1] *= -1.0\n",
    "    d_cam /= np.linalg.norm(d_cam)\n",
    "    d_world = R_wc @ d_cam\n",
    "    d_world /= np.linalg.norm(d_world)\n",
    "    return d_world\n",
    "\n",
    "def unit(v):\n",
    "    v = np.asarray(v, float)\n",
    "    n = np.linalg.norm(v)\n",
    "    return v if n == 0 else v / n\n",
    "\n",
    "# =======================\n",
    "# Hauptablauf\n",
    "# =======================\n",
    "\n",
    "def main():\n",
    "    # ---- Bilder laden\n",
    "    img_paths = list_images(IMG_DIR, IMG_PATTERNS)\n",
    "    img1 = load_rgb(img_paths[0])\n",
    "    img2 = load_rgb(img_paths[1])\n",
    "\n",
    "    # ---- Intrinsics vor Crop\n",
    "    if USE_FOV:\n",
    "        K1 = K_from_fovy(img1.shape, fov_y_deg=26.99, aspect_ratio=11/8.5)\n",
    "\n",
    "        K2 = K_from_fovy(img2.shape, fov_y_deg=26.99, aspect_ratio=11/8.5)\n",
    "\n",
    "    else:\n",
    "        K1 = K_from_sensor_f(img1.shape, F_MM, SENSOR_W_MM, SENSOR_H_MM)\n",
    "        K2 = K_from_sensor_f(img2.shape, F_MM, SENSOR_W_MM, SENSOR_H_MM)\n",
    "\n",
    "    # ---- Optionaler Center-Crop + K anpassen\n",
    "    off1 = (0, 0)\n",
    "    off2 = (0, 0)\n",
    "    if USE_CROP:\n",
    "        img1, off1 = center_crop_to_ar(img1, TARGET_AR)\n",
    "        img2, off2 = center_crop_to_ar(img2, TARGET_AR)\n",
    "        K1 = adjust_K_after_crop(K1, off1)\n",
    "        K2 = adjust_K_after_crop(K2, off2)\n",
    "\n",
    "    # ---- Rote Schwerpunkte finden (v,u!)\n",
    "    (v1, u1), mask1 = find_red_centroid(img1)\n",
    "    (v2, u2), mask2 = find_red_centroid(img2)\n",
    "\n",
    "    # ---- Rotationsmatrizen (Kameras schauen zum Ursprung)\n",
    "    R1 = look_at_R(VC1)\n",
    "    R2 = look_at_R(VC2)\n",
    "\n",
    "    # ---- Strahlenrichtungen in Weltkoordinaten\n",
    "    d1_w = pixel_ray_world(u1, v1, K1, R1, FLIP_IMAGE_Y_TO_CAM)\n",
    "    d2_w = pixel_ray_world(u2, v2, K2, R2, FLIP_IMAGE_Y_TO_CAM)\n",
    "\n",
    "    # ---- „Original“-Richtungen (zum Ursprung) – zum Vergleich\n",
    "    r1_to_origin = unit(-VC1)\n",
    "    r2_to_origin = unit(-VC2)\n",
    "\n",
    "    # =======================\n",
    "    # Plot\n",
    "    # =======================\n",
    "    fig = plt.figure(figsize=(9, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    L = 300.0\n",
    "    t = np.linspace(0.0, 1.0, 2)\n",
    "\n",
    "    # Kamerazentren\n",
    "    ax.scatter([VC1[0]], [VC1[1]], [VC1[2]], s=40, label=\"VC1\")\n",
    "    ax.scatter([VC2[0]], [VC2[1]], [VC2[2]], s=40, label=\"VC2\")\n",
    "    ax.scatter([0], [0], [0], s=40, label=\"World Origin\")\n",
    "    ax.scatter([-10], [25], [25], s=40, label=\"Laser Punkt\")  # optionaler Referenzpunkt\n",
    "\n",
    "    # Ray → Ursprung (dotted)\n",
    "    P1 = VC1 + np.outer(t * L, r1_to_origin)\n",
    "    P2 = VC2 + np.outer(t * L, r2_to_origin)\n",
    "    ax.plot(P1[:, 0], P1[:, 1], P1[:, 2], linestyle=\"dotted\", alpha=0.5, label=\"VC1 → origin\")\n",
    "    ax.plot(P2[:, 0], P2[:, 1], P2[:, 2], linestyle=\"dotted\", alpha=0.5, label=\"VC2 → origin\")\n",
    "\n",
    "    # Gemessene Pixel-Strahlen\n",
    "    Q1 = VC1 + np.outer(t * L, d1_w)\n",
    "    Q2 = VC2 + np.outer(t * L, d2_w)\n",
    "    ax.plot(Q1[:, 0], Q1[:, 1], Q1[:, 2], label=\"VC1 pixel-ray\")\n",
    "    ax.plot(Q2[:, 0], Q2[:, 1], Q2[:, 2], label=\"VC2 pixel-ray\")\n",
    "\n",
    "    # Kleiner Würfel (zur Orientierung)\n",
    "    x = [-25, 25]; y = [0, 50]; z = [-25, 25]\n",
    "    cube = np.array([[xi, yi, zi] for xi in x for yi in y for zi in z])\n",
    "    edges = [(0,1),(0,2),(0,4),(3,1),(3,2),(3,7),(5,1),(5,4),(5,7),(6,2),(6,4),(6,7),(3,6)]\n",
    "    for i,j in edges:\n",
    "        ax.plot([cube[i,0], cube[j,0]], [cube[i,1], cube[j,1]], [cube[i,2], cube[j,2]], color=\"gray\", alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel(\"X\"); ax.set_ylabel(\"Y\"); ax.set_zlabel(\"Z\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    # „Equal-ish“ Aspect\n",
    "    allp = np.vstack([P1, P2, Q1, Q2, VC1[None,:], VC2[None,:], np.zeros((1,3))])\n",
    "    c = (allp.max(0) + allp.min(0)) / 2.0\n",
    "    e = (allp.max(0) - allp.min(0)).max() / 2.0 + 1e-6\n",
    "    ax.set_xlim(c[0]-e, c[0]+e); ax.set_ylim(c[1]-e, c[1]+e); ax.set_zlim(c[2]-e, c[2]+e)\n",
    "    ax.view_init(elev=90, azim=-90)  # gleiche Draufsicht wie im Notebook\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Debug-Ausgabe\n",
    "    print(f\"Bild1 Größe nach Crop: {img1.shape[:2]}  Offset: {off1}  K1:\\n{K1}\")\n",
    "    print(f\"Bild2 Größe nach Crop: {img2.shape[:2]}  Offset: {off2}  K2:\\n{K2}\")\n",
    "    print(f\"COM1 (v,u): {(v1,u1)}   COM2 (v,u): {(v2,u2)}\")\n",
    "    print(f\"Richtungen Welt:\\n  d1={d1_w}\\n  d2={d2_w}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        // There's no need to resize if the WebSocket is not connected:\n        // - If it is still connecting, then we will get an initial resize from\n        //   Python once it connects.\n        // - If it has disconnected, then resizing will clear the canvas and\n        //   never get anything back to refill it, so better to not resize and\n        //   keep something visible.\n        if (fig.ws.readyState != 1) {\n            return;\n        }\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        buttons: event.buttons,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div id='340e09be-8377-45a7-b803-769b793b8419'></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild1 Größe nach Crop: (1760, 1360)  Offset: (1240, 0)  K1:\n",
      "[[6.18216684e+03 0.00000000e+00 6.80000000e+02]\n",
      " [0.00000000e+00 3.66687347e+03 8.80000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Bild2 Größe nach Crop: (1760, 1360)  Offset: (1240, 0)  K2:\n",
      "[[6.18216684e+03 0.00000000e+00 6.80000000e+02]\n",
      " [0.00000000e+00 3.66687347e+03 8.80000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "COM1 (v,u): (1011.6323038397329, 428.72328881469116)   COM2 (v,u): (1013.2235576923077, 543.0861378205128)\n",
      "Richtungen Welt:\n",
      "  d1=[-0.14194256 -0.20826729 -0.96771744]\n",
      "  d2=[ 0.0849937  -0.23453022 -0.9683861 ]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib notebook\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "# -----------------------------\n",
    "# Konfiguration\n",
    "# -----------------------------\n",
    "BASE_DIR = r\"G:\\Meine Ablage\\Studium\\Master\\3. Semester\\Masterprojekt\\Kamera_Simulationen\\Solidworks\\blick auf ursprung\"\n",
    "ASPECT = (8.5, 11)        # (width, height)\n",
    "FOV_X_DEG = 26.99         # horizontaler FoV in Grad (falls dein 26.99° vertikal ist -> Hinweis in compute_K_from_fovx beachten)\n",
    "LOOK_AT = np.array([0.0, 25.0, 0.0])  # Kameras schauen auf (0,25,0)\n",
    "UP_VEC  = np.array([0.0, 1.0, 0.0])   # global \"oben\" = +Y\n",
    "VC1 = np.array([ 25.0, 53.59 + 25, 200.0]) # Kamerazentrum 1\n",
    "VC2 = np.array([-25.0, 53.59 + 25, 200.0]) # Kamerazentrum 2\n",
    "LASER_POINT = np.array([-10.0, 25.0, 25.0])  # optionaler Referenzpunkt aus der Simulation (zum Plot)\n",
    "\n",
    "# Roter Bereich (RGB)\n",
    "LOWER_RED = np.array([100,   0,   0], dtype=np.uint8)\n",
    "UPPER_RED = np.array([255,  80,  80], dtype=np.uint8)\n",
    "\n",
    "# -----------------------------\n",
    "# Hilfsfunktionen Geometrie\n",
    "# -----------------------------\n",
    "def croptoaspect(img, ar):\n",
    "    \"\"\"Center-Crop auf Ziel-Seitenverhältnis ar=(width,height).\"\"\"\n",
    "    h, w, _ = img.shape\n",
    "    target_ratio = ar[0] / ar[1]  # width/height\n",
    "    if (w / h) > target_ratio:\n",
    "        # zu breit -> Breite kürzen\n",
    "        new_w = int(h * target_ratio)\n",
    "        x0 = (w - new_w) // 2; x1 = x0 + new_w\n",
    "        y0, y1 = 0, h\n",
    "    else:\n",
    "        # zu hoch -> Höhe kürzen\n",
    "        new_h = int(w / target_ratio)\n",
    "        y0 = (h - new_h) // 2; y1 = y0 + new_h\n",
    "        x0, x1 = 0, w\n",
    "    return img[y0:y1, x0:x1]\n",
    "\n",
    "def compute_K_from_fovx(W, H, fov_x_deg):\n",
    "    \"\"\"\n",
    "    K aus horizontalem FoV und Bildgröße.\n",
    "    Falls dein gegebener FoV vertikal ist: tausche Rollen von (W,H) und fov_x_deg <-> fov_y_deg analog.\n",
    "    \"\"\"\n",
    "    fov_x = np.deg2rad(fov_x_deg)\n",
    "    # vertikaler FoV aus Aspect Ratio\n",
    "    fov_y = 2.0 * np.arctan((H / W) * np.tan(fov_x / 2.0))\n",
    "\n",
    "    fx = W / (2.0 * np.tan(fov_x / 2.0))\n",
    "    fy = H / (2.0 * np.tan(fov_y / 2.0))\n",
    "    cx, cy = W / 2.0, H / 2.0\n",
    "\n",
    "    K = np.array([[fx, 0.0, cx],\n",
    "                  [0.0, fy, cy],\n",
    "                  [0.0, 0.0, 1.0]], dtype=float)\n",
    "    return K\n",
    "\n",
    "def getR(C, look_at=LOOK_AT, up=UP_VEC):\n",
    "    \"\"\"\n",
    "    Rotationsmatrix R_wc (Spalten = Kameraachsen im Welt-KS),\n",
    "    Kamera schaut von Zentrum C auf look_at; up fixiert den Rollwinkel.\n",
    "    \"\"\"\n",
    "    zc = (look_at - C).astype(float)\n",
    "    zc /= np.linalg.norm(zc)\n",
    "    xc = np.cross(up, zc); xc /= np.linalg.norm(xc)\n",
    "    yc = np.cross(zc, xc)\n",
    "    R_wc = np.column_stack((xc, yc, zc))\n",
    "    return R_wc\n",
    "\n",
    "def pixel_to_camera_ray(u, v, K):\n",
    "    \"\"\"liefert normierten Richtungsvektor im Kamera-KS: d_cam ∝ K^{-1}[u,v,1].\"\"\"\n",
    "    sv = np.array([float(u), float(v), 1.0])\n",
    "    d_cam = np.linalg.inv(K) @ sv\n",
    "    d_cam /= np.linalg.norm(d_cam)\n",
    "    return d_cam\n",
    "\n",
    "def pixel_to_world_ray(com, K, R_wc, C):\n",
    "    \"\"\"\n",
    "    Aus Pixel-Schwerpunkt (v,u) -> Weltstrahl (origin=C, direction=d_world).\n",
    "    center_of_mass liefert (v,u) = (row,col) -> erst auf (u,v) drehen!\n",
    "    \"\"\"\n",
    "    v, u = float(com[0]), float(com[1])\n",
    "    d_cam = pixel_to_camera_ray(u, v, K)\n",
    "    d_world = R_wc @ d_cam\n",
    "    d_world /= np.linalg.norm(d_world)\n",
    "    return C.astype(float), d_world\n",
    "\n",
    "# -----------------------------\n",
    "# Plot-Helper\n",
    "# -----------------------------\n",
    "def set_axes_equal(ax):\n",
    "    \"\"\"Gleiche Skalierung für alle 3 Achsen (würfelförmiger Ausschnitt).\"\"\"\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    max_range = max([x_range, y_range, z_range]) / 2.0\n",
    "    x_middle = np.mean(x_limits); y_middle = np.mean(y_limits); z_middle = np.mean(z_limits)\n",
    "    ax.set_xlim3d([x_middle - max_range, x_middle + max_range])\n",
    "    ax.set_ylim3d([y_middle - max_range, y_middle + max_range])\n",
    "    ax.set_zlim3d([z_middle - max_range, z_middle + max_range])\n",
    "\n",
    "def plot_ray(ax, base, direction, scale=300, label=None, color=None, ls='--', alpha=0.9):\n",
    "    base = np.asarray(base, float)\n",
    "    d = np.asarray(direction, float)\n",
    "    n = np.linalg.norm(d);\n",
    "    if n == 0: return\n",
    "    d = d / n\n",
    "    pts = np.vstack([base, base + scale * d])\n",
    "    ax.plot(pts[:,0], pts[:,1], pts[:,2], label=label, color=color, linestyle=ls, alpha=alpha)\n",
    "\n",
    "def plotvec_from_origin(ax, v, label=None, color=None, ls='-'):\n",
    "    v = np.asarray(v, float)\n",
    "    ax.plot((0, v[0]), (0, v[1]), (0, v[2]), label=label, color=color, linestyle=ls)\n",
    "\n",
    "def plotcube(ax):\n",
    "    # Quader um den Ursprung: X∈[-25,25], Y∈[0,50], Z∈[-25,25]\n",
    "    x = [-25, 25]; y = [0, 50]; z = [-25, 25]\n",
    "    cube_points = np.array([[xi, yi, zi] for xi in x for yi in y for zi in z], float)\n",
    "    edges = [(0,1), (0,2), (0,4), (3,1), (3,2), (3,7),\n",
    "             (5,1), (5,4), (5,7), (6,2), (6,4), (6,7), (3,6)]\n",
    "    for i,j in edges:\n",
    "        ax.plot([cube_points[i,0], cube_points[j,0]],\n",
    "                [cube_points[i,1], cube_points[j,1]],\n",
    "                [cube_points[i,2], cube_points[j,2]],\n",
    "                color=\"gray\", linewidth=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Bilder suchen & laden\n",
    "# -----------------------------\n",
    "patterns = [os.path.join(BASE_DIR, \"**\", ext) for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\")]\n",
    "images = []\n",
    "for pat in patterns:\n",
    "    images.extend(glob.glob(pat, recursive=True))\n",
    "images = sorted(images)\n",
    "if len(images) < 2:\n",
    "    raise RuntimeError(\"Weniger als 2 Bilder gefunden.\")\n",
    "\n",
    "img1 = cv2.cvtColor(cv2.imread(images[0]), cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(cv2.imread(images[1]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Crop auf Aspect\n",
    "img1_c = croptoaspect(img1, ASPECT)\n",
    "img2_c = croptoaspect(img2, ASPECT)\n",
    "\n",
    "H, W = img1_c.shape[:2]\n",
    "\n",
    "# -----------------------------\n",
    "# Rote Pixel -> Schwerpunkt\n",
    "# -----------------------------\n",
    "mask1 = cv2.inRange(img1_c, LOWER_RED, UPPER_RED)\n",
    "mask2 = cv2.inRange(img2_c, LOWER_RED, UPPER_RED)\n",
    "com1 = ndimage.center_of_mass(mask1)  # (v,u)\n",
    "com2 = ndimage.center_of_mass(mask2)  # (v,u)\n",
    "\n",
    "print(\"Bildgröße (W,H):\", W, H)\n",
    "print(\"COM1 (v,u):\", com1, \" | COM2 (v,u):\", com2)\n",
    "\n",
    "# optional kontroll-Plot Maske + Kreuz\n",
    "cm = np.bitwise_or(mask1, mask2).copy()\n",
    "v1, u1 = map(int, com1); v2, u2 = map(int, com2)\n",
    "cv2.drawMarker(cm, (u1, v1), 255, markerType=cv2.MARKER_CROSS, markerSize=21, thickness=2)\n",
    "cv2.drawMarker(cm, (u2, v2), 255, markerType=cv2.MARKER_CROSS, markerSize=21, thickness=2)\n",
    "# plt.imshow(cm, cmap='gray', vmin=0, vmax=255); plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# K, R, Strahlen\n",
    "# -----------------------------\n",
    "K = compute_K_from_fovx(W, H, FOV_X_DEG)\n",
    "R1 = getR(VC1, LOOK_AT, UP_VEC)\n",
    "R2 = getR(VC2, LOOK_AT, UP_VEC)\n",
    "\n",
    "origin1, d_world1 = pixel_to_world_ray(com1, K, R1, VC1)\n",
    "origin2, d_world2 = pixel_to_world_ray(com2, K, R2, VC2)\n",
    "\n",
    "# optional: Check Winkel zum Laserpunkt\n",
    "def angle_to_point(origin, d, P):\n",
    "    v = (P - origin); v /= np.linalg.norm(v)\n",
    "    return np.degrees(np.arccos(np.clip(np.dot(d, v), -1, 1)))\n",
    "ang1 = angle_to_point(origin1, d_world1, LASER_POINT)\n",
    "ang2 = angle_to_point(origin2, d_world2, LASER_POINT)\n",
    "print(f\"Winkel Cam1-Ray -> Laserpunkt: {ang1:.3f}°\")\n",
    "print(f\"Winkel Cam2-Ray -> Laserpunkt: {ang2:.3f}°\")\n",
    "\n",
    "# -----------------------------\n",
    "# Plot\n",
    "# -----------------------------\n",
    "fig = plt.figure(figsize=(8,7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.set_box_aspect([1,1,1])\n",
    "\n",
    "# Kamerazentren\n",
    "ax.scatter([VC1[0]], [VC1[1]], [VC1[2]], s=40, label=\"VC1\")\n",
    "ax.scatter([VC2[0]], [VC2[1]], [VC2[2]], s=40, label=\"VC2\")\n",
    "ax.scatter([0], [0], [0], s=30, label=\"World Origin\")\n",
    "ax.scatter([LOOK_AT[0]],[LOOK_AT[1]],[LOOK_AT[2]], s=30, label=\"look_at\")\n",
    "\n",
    "# Ursprungswürfel\n",
    "plotcube(ax)\n",
    "\n",
    "# Grobe Richtungen der Kamerazentren von Ursprung aus (nur zur Orientierung)\n",
    "plotvec_from_origin(ax, VC1, label=\"VC1 (vom Ursprung)\", color=\"C2\")\n",
    "plotvec_from_origin(ax, VC2, label=\"VC2 (vom Ursprung)\", color=\"C3\")\n",
    "\n",
    "# Strahlen (aus Pixel-Schwerpunkten)\n",
    "plot_ray(ax, origin1, d_world1, scale=300, label=\"Cam1 Ray\", color=\"C0\", ls=\"--\", alpha=0.8)\n",
    "plot_ray(ax, origin2, d_world2, scale=300, label=\"Cam2 Ray\", color=\"C1\", ls=\"--\", alpha=0.8)\n",
    "\n",
    "# Optional: Laserpunkt\n",
    "ax.scatter([LASER_POINT[0]], [LASER_POINT[1]], [LASER_POINT[2]],\n",
    "           color='red', s=30, label=\"Laser Punkt\")\n",
    "\n",
    "# Achsen & Ansicht\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.view_init(elev=90, azim=-90)  # XY-Ansicht (Z nach oben). Passe bei Bedarf an.\n",
    "ax.legend(loc=\"best\")\n",
    "set_axes_equal(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "60eee34b1b931a91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
